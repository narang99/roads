{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a8f9d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30c71a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "542c80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 5000\n",
    "\n",
    "DS = Path(\"../../datasets/\")\n",
    "BASE_T004 = DS / \"T004-taco-crops\"\n",
    "BASE_DS_DIR = BASE_T004 / \"V2\"\n",
    "TEST_BIG_IMG = BASE_DS_DIR / \"14325.jpeg\"\n",
    "# EXP_BASE = BASE_DS_DIR / PROJECT_CODE\n",
    "# OUTS = BASE_DS_DIR / \"synth\"\n",
    "# LOG_BASE = EXP_BASE / \"log\"\n",
    "# TACO_BASE_DIR = Path(\"/Users/hariomnarang/Desktop/personal/TACO/data/\")\n",
    "# ANN_FILE = TACO_BASE_DIR / \"annotations.json\"\n",
    "\n",
    "# LOG_BASE.mkdir(parents=True, exist_ok=True)\n",
    "# DS.exists(), TACO_BASE_DIR.exists(), ANN_FILE.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "089be1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'002'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# im assuming hte model is good, we only rename whatever is done\n",
    "\n",
    "def _is_numeric_dir(d):\n",
    "    try:\n",
    "        int(d.name)\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def _get_max_num_dir():\n",
    "    r = []\n",
    "    for d in BASE_DS_DIR.glob(\"*\"):\n",
    "        if not d.is_dir():\n",
    "            continue\n",
    "        if _is_numeric_dir(d):\n",
    "            r.append(int(d.name))\n",
    "    if not r:\n",
    "        return 1\n",
    "    return max(r)\n",
    "\n",
    "def _num_to_dir(n):\n",
    "    return f\"{n:03d}\"\n",
    "\n",
    "def _next_dir_name():\n",
    "    existing_max = _get_max_num_dir()\n",
    "    return _num_to_dir(existing_max + 1)\n",
    "\n",
    "_next_dir_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3040e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import json\n",
    "import csv\n",
    "from typing import Optional\n",
    "\n",
    "def _dict_to_markdown_table(d):\n",
    "    keys = list(d.keys())\n",
    "    vals = list(d.values())\n",
    "\n",
    "    max_key = max(len(str(k)) for k in keys + [\"Key\"])\n",
    "    max_val = max(len(str(v)) for v in vals + [\"Value\"])\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f\"| {'Key'.ljust(max_key)} | {'Value'.ljust(max_val)} |\")\n",
    "    lines.append(f\"|{'-' * (max_key + 2)}|{'-' * (max_val + 2)}|\")\n",
    "\n",
    "    for k, v in d.items():\n",
    "        lines.append(f\"| {str(k).ljust(max_key)} | {str(v).ljust(max_val)} |\")\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "class ParsedDir:\n",
    "    def __init__(\n",
    "        self, orig_path, params\n",
    "    ):\n",
    "        self.orig_path = orig_path\n",
    "        self.params = params\n",
    "\n",
    "    @classmethod\n",
    "    def parse(cls, dir_path) -> \"ParsedDir\":\n",
    "        res = {}\n",
    "        parts = dir_path.name.split(\"-\")\n",
    "        for part in parts:\n",
    "            try:\n",
    "                k, v = part.split(\"=\")\n",
    "            except Exception as ex:\n",
    "                raise Exception(f\"part: {part}\") from ex\n",
    "            res[k] = v\n",
    "        return cls(dir_path, res)\n",
    "    \n",
    "    def get_img_size(self) -> Optional[int]:\n",
    "        try:\n",
    "            return int(self.params[\"FILE_SIZE\"])\n",
    "        except Exception as ex:\n",
    "            print(f\"could not get image size for {self.orig_path} reason={ex}\")\n",
    "            return None\n",
    "\n",
    "    @property\n",
    "    def export_pkl(self):\n",
    "        return self.orig_path / \"log\" / \"export.pkl\"\n",
    "\n",
    "    @property\n",
    "    def history(self):\n",
    "        return self.orig_path / \"log\" / \"history.csv\"\n",
    "\n",
    "    @property\n",
    "    def result_png(self):\n",
    "        return self.orig_path / \"res.png\"\n",
    "\n",
    "    def dump(self, new_dir, dry_run=True):\n",
    "        dest = self.orig_path / \"README.md\"\n",
    "        content = self._get_content_readme()\n",
    "        print(content)\n",
    "        print(f\"writing to {dest}\")\n",
    "        if not dry_run:\n",
    "            self._dump_params(self.orig_path / \"params.json\")\n",
    "            with open(dest, \"a\") as f:\n",
    "                f.write(content)\n",
    "\n",
    "        new_dir = Path(new_dir)\n",
    "        print(f\"Move: {self.orig_path} -> {new_dir}\")\n",
    "        if not dry_run:\n",
    "            shutil.move(self.orig_path, new_dir)\n",
    "\n",
    "    def _get_content_readme(self):\n",
    "        content = \"\\n# Params\\n\\n\"\n",
    "        content += _dict_to_markdown_table(self.params)\n",
    "    \n",
    "        if self.history.exists():\n",
    "            content += \"\\n\\n---\"\n",
    "            content += \"\\n\\n# History\"\n",
    "            content += \"\\n\\n\"\n",
    "            content += csv_to_markdown(self.history)\n",
    "            content += \"\\n\\n---\"\n",
    "        return content\n",
    "\n",
    "    def _dump_params(self, path):\n",
    "        with open(path, \"w\")as f:\n",
    "            json.dump(self.params, f)\n",
    "\n",
    "def csv_to_markdown(path):\n",
    "    with open(path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        rows = list(csv.reader(f))\n",
    "\n",
    "    if not rows:\n",
    "        return \"\"\n",
    "\n",
    "    cols = len(rows[0])\n",
    "    widths = [\n",
    "        max(len(row[i]) if i < len(row) else 0 for row in rows)\n",
    "        for i in range(cols)\n",
    "    ]\n",
    "\n",
    "    def fmt(row):\n",
    "        return \"| \" + \" | \".join(\n",
    "            (row[i] if i < len(row) else \"\").ljust(widths[i])\n",
    "            for i in range(cols)\n",
    "        ) + \" |\"\n",
    "\n",
    "    header = fmt(rows[0])\n",
    "    sep = \"| \" + \" | \".join(\"-\" * w for w in widths) + \" |\"\n",
    "    body = \"\\n\".join(fmt(r) for r in rows[1:])\n",
    "\n",
    "    return \"\\n\".join([header, sep, body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7cbde77",
   "metadata": {},
   "outputs": [],
   "source": [
    "drs = filter(Path.is_dir, BASE_DS_DIR.glob(\"*\"))\n",
    "drs = filter(lambda d: not _is_numeric_dir(d), drs)\n",
    "drs = filter(lambda d: d.name.startswith(\"FINE_TUNE\"), drs)\n",
    "drs = map(ParsedDir.parse, drs)\n",
    "drs = filter(lambda dr: dr.export_pkl.exists(), drs)\n",
    "drs = list(drs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2bc4a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(drs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97054ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create res png if it does not exist\n",
    "from tqdm import tqdm\n",
    "from mtrain.smallnet.predict import tile_image_and_predict\n",
    "from fastai.vision.all import load_learner\n",
    "\n",
    "def make_res_pngs(drs, dry_run=True):\n",
    "    for dr in tqdm(drs):\n",
    "        sz = dr.get_img_size()\n",
    "        if dry_run:\n",
    "            print(f\"run inference: {dr.orig_path} size={sz}\")\n",
    "        else:\n",
    "            learn = load_learner(dr.export_pkl)\n",
    "            if sz:\n",
    "                res = tile_image_and_predict(TEST_BIG_IMG, learn, sz, add_labels=False)\n",
    "                plt.imsave(dr.result_png, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3d0805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]/Users/hariomnarang/Desktop/personal/roads/mtrain/.venv/lib/python3.12/site-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
      "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
      "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
      "100%|██████████| 192/192 [00:09<00:00, 20.81it/s]\n",
      "100%|██████████| 660/660 [00:29<00:00, 22.13it/s]\n",
      "100%|██████████| 70/70 [00:03<00:00, 17.93it/s]\n",
      "100%|██████████| 99/99 [00:05<00:00, 19.22it/s]\n",
      "100%|██████████| 520/520 [00:24<00:00, 20.93it/s]\n",
      "100%|██████████| 414/414 [00:17<00:00, 23.70it/s]\n",
      "100%|██████████| 336/336 [00:14<00:00, 23.50it/s]\n",
      "100%|██████████| 266/266 [00:11<00:00, 23.32it/s]\n",
      "100%|██████████| 130/130 [00:05<00:00, 21.84it/s]\n",
      "100%|██████████| 2028/2028 [01:21<00:00, 25.02it/s]\n",
      "100%|██████████| 660/660 [00:26<00:00, 24.98it/s]\n",
      "100%|██████████| 910/910 [00:32<00:00, 27.94it/s]\n",
      "100%|██████████| 336/336 [00:13<00:00, 24.43it/s]\n",
      "100%|██████████| 13/13 [04:37<00:00, 21.34s/it]\n"
     ]
    }
   ],
   "source": [
    "make_res_pngs(drs, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac0dd72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dr in drs:\n",
    "    if not dr.orig_path.exists():\n",
    "        # already moved\n",
    "        continue\n",
    "        \n",
    "    if dr.result_png.exists() and dr.export_pkl.exists() and dr.history.exists():\n",
    "        next_dir = BASE_DS_DIR / _next_dir_name()\n",
    "        dr.dump(next_dir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9eeca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class DumpedDir:\n",
    "    def __init__(self, d: Path, params: dict):\n",
    "        self.d = d\n",
    "        self.params = params\n",
    "\n",
    "    def dump_params(self):\n",
    "        with open(self.d / \"params.json\", \"w\") as f:\n",
    "            json.dump(self.params, f)\n",
    "\n",
    "    @classmethod\n",
    "    def parse_markdown(cls, d: Path):\n",
    "        mkd = d / \"README.md\"\n",
    "        if not mkd.exists():\n",
    "            return None\n",
    "        with open(mkd) as f:\n",
    "            params, _ = parse_markdown_params_and_history(f.read())\n",
    "        return cls(d, params)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_params(cls, d: Path):\n",
    "        params = d / \"params.json\"\n",
    "        if not params.exists():\n",
    "            raise Exception(f\"params not found {params}\")\n",
    "        with open(params) as f:\n",
    "            params = json.load(f)\n",
    "        return cls(d, params)\n",
    "        \n",
    "def parse_markdown_params_and_history(md):\n",
    "    def parse_table(lines):\n",
    "        header = [h.strip() for h in lines[0].strip(\"|\").split(\"|\")]\n",
    "        rows = []\n",
    "        for line in lines[2:]:  # skip header + separator\n",
    "            vals = [v.strip() for v in line.strip(\"|\").split(\"|\")]\n",
    "            rows.append(dict(zip(header, vals)))\n",
    "        return rows\n",
    "\n",
    "    lines = [l.rstrip() for l in md.splitlines()]\n",
    "    tables = []\n",
    "    current = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.startswith(\"|\"):\n",
    "            current.append(line)\n",
    "        else:\n",
    "            if current:\n",
    "                tables.append(current)\n",
    "                current = []\n",
    "    if current:\n",
    "        tables.append(current)\n",
    "\n",
    "    params_rows = parse_table(tables[0])\n",
    "    history_rows = parse_table(tables[1])\n",
    "\n",
    "    params = {row[\"Key\"]: row[\"Value\"] for row in params_rows}\n",
    "\n",
    "    return params, history_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6c1039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps = BASE_DS_DIR.glob(\"*\")\n",
    "dumps = filter(Path.is_dir, dumps)\n",
    "dumps = filter(_is_numeric_dir, dumps)\n",
    "dumps = filter(lambda d: int(d.name) >= 6, dumps)\n",
    "dumps = map(DumpedDir.parse_markdown, dumps)\n",
    "dumps = list(dumps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "600d3657",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dumps:\n",
    "    d.dump_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45edd199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
